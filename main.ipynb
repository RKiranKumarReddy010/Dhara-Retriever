{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from numba import cuda,jit\n",
    "import cupy as cp\n",
    "import bs4\n",
    "import chromadb\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import LLMResult\n",
    "import sys\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingStdOutCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        sys.stdout.write(token)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.01)  # Add a small delay to simulate typing\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local = ChatOllama(model='llama3')\n",
    "#client1 = chromadb.PersistentClient(path=\"./vectorstore1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def load_document(path): \n",
    "    document_loader = PyPDFDirectoryLoader(path)\n",
    "    return document_loader.load()\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection = client.create_collection(name=\"rag-chroma1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\7434402.pdf', 'page': 1}, page_content='IUIUIUIUIUIUIUIUIUIUIUIUIUIUIU!UIUIUIUIUIUIOlO!CJT\\nTheGanges\\ninMythandHistory')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t=Training\n",
    "path= 'data'\n",
    "document = load_document(path)\n",
    "document[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=7500, chunk_overlap=100)\n",
    "doc_split = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "with cp.cuda.Device(0):\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_split,\n",
    "        embedding=OllamaEmbeddings(model='nomic-embed-text'),\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRAN\\Documents\\ML\\Dhara\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_callback = StreamingStdOutCallbackHandler()\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "loaded_vectorstore = Chroma(persist_directory=\"./chroma_db1\", embedding_function=embeddings)\n",
    "loaded_vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever = vectorstore.as_retriever()\n",
    "retriever = loaded_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'before_rag_template = \"{topic}\"\\nprint(\"Before using RAG:\")\\nbefore_rag_prompt = ChatPromptTemplate.from_template(before_rag_template)\\nbefore_rag_chain = before_rag_prompt | model_local | StrOutputParser()\\nprint(before_rag_chain.invoke({\"topic\":\"What is proposed in the paper Attention is All You Need ?\"}))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''before_rag_template = \"{topic}\"\n",
    "print(\"Before using RAG:\")\n",
    "before_rag_prompt = ChatPromptTemplate.from_template(before_rag_template)\n",
    "before_rag_chain = before_rag_prompt | model_local | StrOutputParser()\n",
    "print(before_rag_chain.invoke({\"topic\":\"What is proposed in the paper Attention is All You Need ?\"}))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_rag_template = \"\"\"answer the question based on the following context:\n",
    "{context}\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)\n",
    "after_rag_chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "     | after_rag_prompt\n",
    "     | model_local\n",
    "     | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'callbacks' is an invalid keyword argument for print()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mafter_rag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasons behind the pollution of ganga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstreaming_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'callbacks' is an invalid keyword argument for print()"
     ]
    }
   ],
   "source": [
    "print(after_rag_chain.invoke(\"reasons behind the pollution of ganga\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
