{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#ollama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from numba import cuda,jit\n",
    "import cupy as cp\n",
    "import bs4\n",
    "import chromadb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local = ChatOllama(model='llama3')\n",
    "#client1 = chromadb.PersistentClient(path=\"./vectorstore1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(path): \n",
    "    document_loader = PyPDFDirectoryLoader(path)\n",
    "    return document_loader.load()\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection = client.create_collection(name=\"rag-chroma1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\7434402.pdf', 'page': 1}, page_content='IUIUIUIUIUIUIUIUIUIUIUIUIUIUIU!UIUIUIUIUIUIOlO!CJT\\nTheGanges\\ninMythandHistory')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= 'data'\n",
    "document = load_document(path)\n",
    "document[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=7500, chunk_overlap=100)\n",
    "doc_split = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cp.cuda.Device(0):\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_split,\n",
    "        embedding=OllamaEmbeddings(model='nomic-embed-text'),\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIRAN\\Documents\\ML\\Dhara\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "loaded_vectorstore = Chroma(persist_directory=\"./chroma_db1\", embedding_function=embeddings)\n",
    "loaded_vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever = vectorstore.as_retriever()\n",
    "retriever = loaded_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'before_rag_template = \"{topic}\"\\nprint(\"Before using RAG:\")\\nbefore_rag_prompt = ChatPromptTemplate.from_template(before_rag_template)\\nbefore_rag_chain = before_rag_prompt | model_local | StrOutputParser()\\nprint(before_rag_chain.invoke({\"topic\":\"What is proposed in the paper Attention is All You Need ?\"}))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''before_rag_template = \"{topic}\"\n",
    "print(\"Before using RAG:\")\n",
    "before_rag_prompt = ChatPromptTemplate.from_template(before_rag_template)\n",
    "before_rag_chain = before_rag_prompt | model_local | StrOutputParser()\n",
    "print(before_rag_chain.invoke({\"topic\":\"What is proposed in the paper Attention is All You Need ?\"}))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_rag_template = \"\"\"answer the question based on the following context:\n",
    "{context}\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)\n",
    "after_rag_chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "     | after_rag_prompt\n",
    "     | model_local\n",
    "     | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, I'll provide an answer to the question \"Reasons behind the pollution of Ganga\".\n",
      "\n",
      "The GangƒÅ River, considered sacred in Hinduism, has been facing severe pollution issues for decades. Some of the key reasons contributing to its pollution are:\n",
      "\n",
      "1. **Urbanization and Industrialization**: The rapid growth of cities like Kanpur, Varanasi, and Allahabad along the riverbanks has led to increased industrial and domestic waste disposal into the river.\n",
      "2. **Agricultural Runoff**: Chemical pesticides, fertilizers, and other agricultural pollutants have entered the river through runoff from fields and agricultural activities.\n",
      "3. **Sewage Disposal**: Inadequate sewage treatment facilities and lack of proper waste management systems in cities and towns along the Ganges basin have led to untreated sewage flowing into the river.\n",
      "4. **Human Waste**: The large number of religious bathing sites, temples, and ghats along the riverbanks have contributed to a significant amount of human waste entering the water body.\n",
      "5. **Lack of Regulation**: Inadequate enforcement of pollution control laws and regulations has allowed industries, households, and municipalities to continue polluting the river with impunity.\n",
      "6. **Population Growth**: The growing population in cities and towns along the Ganges basin has led to increased pressure on the river's water resources, resulting in more wastewater being discharged into it.\n",
      "7. **Lack of Proper Waste Management**: Inadequate waste management infrastructure and practices have led to a significant amount of plastic, hazardous waste, and other pollutants entering the river.\n",
      "\n",
      "These factors have cumulatively contributed to the severe pollution of the Ganges River, posing significant threats to its ecosystem, human health, and cultural heritage.\n"
     ]
    }
   ],
   "source": [
    "with cp.cuda.Device(0):\n",
    "    print(after_rag_chain.invoke(\"reasons behind the pollution of ganga\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
